{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c965173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run script to train with kindergarten cl\n",
    "\n",
    "from dynamics.process.rnn import fulltrain\n",
    "\n",
    "#location of repo\n",
    "workdir='~/projects/kind_cl/'\n",
    "\n",
    "#location of config file\n",
    "cfgname='/Users/dhocker/projects/kind_cl/demo/33.cfg'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e5109a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops\n",
      "{'gamma': 0.95, 'alpha': 0.0001, 'lam': 2.5, 'pcatch': 0.2, 'ctmax': 500, 'blocklength': 40, 'freeze': False, 'state_resetfreq': 160, 'p_statereset': 1.0, 'prog_stop': False, 'envtype': 'wt_env_wITI_batchedreward', 'iti_determ': 1, 'iti_random': 20, 'iti_type': 'uniform', 'pblock': 0.5, 'stagelist_cl': ['stage1.cfg'], 'trainonly': True, 'tracktheta': False, 'trackstate': False, 'plot': False, 'device': 'cpu', 'Vvec': [5, 10, 20, 40, 80], 'Vvec_low': [5, 10, 20], 'Vvec_high': [20, 40, 80], 'Ract': -2.0, 'w': -0.05, 'win': 20, 'R_vio': -1.0, 'seed': 101, 'ns': 10000, 'T': 30, 'dt': 0.05, 'blocklen': 40, 'useblocks': True, 'displevel': 4, 'inputcase': 11, 'batchsize': 1, 'snr': [0.0, 0.0, 0.0, 0.0], 'snr_hidden': 0.0, 'p_vio': 0.0, 'T_vio': 0.1, 'rnntype': 'LSTM', 'dropout': 0.0, 'modeltype': 'RNNModel_multiregion_2allt', 'costtype': 'loss_actorcritic_regularized_9', 'ismultiregion': True, 'rank': [None, None], 'kindergarten_prediction': True, 'nocatch_force': False, 'alpha_rho': 0.3, 'alpha_rho_av': 0.05, 'lambda_policy': 1.0, 'lambda_value': 0.0005, 'lambda_entropy': 0.05, 'lambda_pred': 0.5, 'anneal_type': 'none', 'gamma_kindergarten': 0.0001, 'lambda_supervised': 10.0, 'seed_kindergarten': 0, 'lossinds_kindergarten': [0, 1, 2], 'batchsize_kindergarten': 1000, 'stages_kindergarten': ['simple', 'intermediate'], 'nepoch_kindergarten': 10000, 'stopargs_int_kindergarten': 0.001, 'base_epoch_kind': 1000, 'lambda_supervised_list': [10.0, 10.0, 10.0], 'nsteps_simple_kindergarten': 20, 'nsteps_train_simple_kindergarten': 20, 'kind_vals': [5, 10, 20, 40, 80], 'nsteps_list_kindergarten': [20, 25], 'nsteps_list_int': array([31, 90, 83, 95, 29, 97, 60, 24, 83, 60]), 'highvartrials_kind': False, 'nsteps_train_int': 652, 'stoparg_simple': 30.0, 'stoptype_simple': 'converge', 'numstates_pred': 3, 'pred_stoparg': 0.2, 'pred_stoptype': 'lowlim', 'beta_pred_kindpred': 0.5, 'beta_supervised_kindpred': 1.0, 'lossinds_supervised_kindpred': [0, 1, 2], 'lossinds_pred': 3, 'batchsize_pred': 20, 'ntrials_pred': 400, 'gamma_pred': 0.005, 'nepoch_pred': 10000, 'base_epoch_pred': 20, 'pred_updatefun': 'update_trialstart', 'blocklength_pred': 50, 'lam_pred': 2.5, 'kindergarten_d2m': False, 'd2m_p': 0.5, 'lambda_d2m': 0.0, 'beta_d2m_kindd2m': 1.0, 'base_epoch_d2m': 100, 'gamma_d2m': 0.001, 'beta_pred_d2m': 0.0, 'beta_supervised_kindd2m': 0.0, 'batchsize_d2m': 1000, 'tmin_d2m': 0.1, 'tmax_d2m': 5, 'nepoch_d2m': 10000, 'd2m_updatefun': 'update_both', 'lossinds_supervised_kindd2m': [1, 2], 'd2m_stoptype': 'lowlim', 'd2m_stoparg': 0.01, 'pstim_prop': 0.4, 'pstim_amp': 1.0, 'nn': [256, 256]}\n",
      "uniqueops\n",
      "{'netseed': 33, 'device': 'cpu', 'savedir': '/Users/dhocker/projects/kind_cl/demo/', 'modelname': '', 'nn': [256, 256], 'bias': 0.0, 'nrounds1': 10, 'nrounds2': 10, 'nrounds3': 10, 'nrounds1_s': 0, 'nrounds2_s': 0, 'nrounds3_s': 0, 'usekindergarten': True, 'roundstart_pred': 0, 'adam_fname': ''}\n",
      "choosing model type\n",
      "moving model to device\n",
      "saving initial network\n",
      "deciding on pre-processing steps\n",
      "beginning kindergarten\n",
      "2025-02-20 13:52:37.724956\n",
      "/Users/dhocker/projects/kind_cl/demo/rnn_kindergarten_33\n",
      "training on simple task\n",
      "task inds for training:\n",
      "[[0], [1, 0], [2, 1, 0]]\n",
      "training on output dims:[0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fulltrain\u001b[38;5;241m.\u001b[39mfulltrain_run(cfgname)\n",
      "File \u001b[0;32m~/projects/dynamics/dynamics/process/rnn/fulltrain.py:62\u001b[0m, in \u001b[0;36mfulltrain_run\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m     60\u001b[0m     savename \u001b[38;5;241m=\u001b[39m savedir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrnn_kindergarten_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(netseed)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(savename)\n\u001b[0;32m---> 62\u001b[0m     net, _, _, optim_fname \u001b[38;5;241m=\u001b[39m wt_protocols\u001b[38;5;241m.\u001b[39mtraining_kindergarten(net, ops\u001b[38;5;241m=\u001b[39mops, savename\u001b[38;5;241m=\u001b[39msavename, device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     63\u001b[0m                                                                 savelog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, optim_fname\u001b[38;5;241m=\u001b[39moptim_fname)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ops[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkindergarten_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkindergarten + prediction\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/dynamics/dynamics/process/rnn/wt_protocols.py:324\u001b[0m, in \u001b[0;36mtraining_kindergarten\u001b[0;34m(net, ops, savename, device, savelog, optim_fname)\u001b[0m\n\u001b[1;32m    321\u001b[0m     si\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# train, round 1\u001b[39;00m\n\u001b[0;32m--> 324\u001b[0m ltot_train, grad_norm, outptdict \u001b[38;5;241m=\u001b[39m wt_kindergarten\u001b[38;5;241m.\u001b[39mtrain(net, updater, si, inputs, targets, device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    325\u001b[0m                                                          nepoch\u001b[38;5;241m=\u001b[39mnepoch, nsteps\u001b[38;5;241m=\u001b[39mnsteps_train_simple,\n\u001b[1;32m    326\u001b[0m                                                          lossinds\u001b[38;5;241m=\u001b[39mlossinds, stoptype\u001b[38;5;241m=\u001b[39mstoptype_simple,\n\u001b[1;32m    327\u001b[0m                                                          stopargs\u001b[38;5;241m=\u001b[39mstoparg_simple)\n\u001b[1;32m    329\u001b[0m ltot_train_list_simple\u001b[38;5;241m.\u001b[39mappend(ltot_train)\n\u001b[1;32m    330\u001b[0m gradnorm_list_simple\u001b[38;5;241m.\u001b[39mappend(grad_norm)\n",
      "File \u001b[0;32m~/projects/dynamics/dynamics/process/rnn/wt_kindergarten.py:375\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, updater, si, inp, targ, device, nepoch, nsteps, lossinds, stoptype, stopargs, win, chkptepoch)\u001b[0m\n\u001b[1;32m    372\u001b[0m targets_k \u001b[38;5;241m=\u001b[39m targets[:, ind:ind \u001b[38;5;241m+\u001b[39m nsteps, :]\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# generate samples\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m outputs, state, net \u001b[38;5;241m=\u001b[39m batchsamples(net, inputs_k, state, device)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# update\u001b[39;00m\n\u001b[1;32m    378\u001b[0m loss_k \u001b[38;5;241m=\u001b[39m update(updater, outputs, targets_k, lossinds)\n",
      "File \u001b[0;32m~/projects/dynamics/dynamics/process/rnn/wt_kindergarten.py:255\u001b[0m, in \u001b[0;36mbatchsamples\u001b[0;34m(net, inputs, si, device)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# parse inputs, mostly for multiregion\u001b[39;00m\n\u001b[1;32m    252\u001b[0m inputs \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mparseiputs(inputs)\n\u001b[0;32m--> 255\u001b[0m output \u001b[38;5;241m=\u001b[39m net(inputs, si, isITI\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# assume that all models will augment action space for ITI\u001b[39;00m\n\u001b[1;32m    256\u001b[0m state \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# state of network\u001b[39;00m\n\u001b[1;32m    257\u001b[0m pred_supervised \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_supervised\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# supervised output predicitons for kindergarten\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torchenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/dynamics/dynamics/process/rnn/wt_nets.py:755\u001b[0m, in \u001b[0;36mRNNModel_multiregion_2.forward\u001b[0;34m(self, inputs, state, isITI, device)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# TODO: functional? this will be hard to write modular for gru and vanilla RNN\u001b[39;00m\n\u001b[1;32m    753\u001b[0m     inp2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((inputs[\u001b[38;5;241m1\u001b[39m], ofc_output),\n\u001b[1;32m    754\u001b[0m                      dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# just entire state for GRU and vanilla RNN\u001b[39;00m\n\u001b[0;32m--> 755\u001b[0m Y2, state2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn2(inp2, state[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    757\u001b[0m \u001b[38;5;66;03m# add noise to state2\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnntype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torchenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torchenv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fulltrain.fulltrain_run(cfgname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8256c9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
