{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c2df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis for Fig 6d-e, Fig S7\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import copy\n",
    "from scipy.io import savemat\n",
    "from scipy.linalg import schur\n",
    "from sklearn.cluster import DBSCAN as dbscan\n",
    "#from dynamics.process.rnn.parse import KEconvert2matlab\n",
    "from scipy.stats import ranksums, wilcoxon,ks_2samp\n",
    "import glob\n",
    "import warnings\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from os.path import exists\n",
    "from scipy import interpolate\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "sys.path.insert(0, '/Users/dhocker/projects/kind_cl/')\n",
    "\n",
    "from dynamics.process.rnn import wt_kindergarten, wt_nets, wt_costs, wt_reinforce_cont_new, wt_pred, parse, parse_state\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Trying to unpickle estimator PCA*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f4f6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KEconvert2matlab(fname, dosave=True, eps=3, doadaptive=False, savedir=None):\n",
    "    \"\"\"\n",
    "    extracts the fixed and slow points from KE minization file, clusters with DBSCAN,\n",
    "    then converts to a matlab file\n",
    "    :param fname: file name of kinetic energy minima located by minimization\n",
    "    :param dosave: if true, saves .mat file. otherwise just returns dict\n",
    "    :param eps: the DBscan parameter\n",
    "    :param doadaptive: should the epsilon parameter be chosen adaptive for each network, based on PC1 range?\n",
    "    :param savedir: if None, save in original data dir. this helps for trying different hyperparams\n",
    "    :return: (dict) of coordinates, schur modes, eigenvalues, etc.\n",
    "    \"\"\"\n",
    "\n",
    "    if not exists(fname):\n",
    "        #print('data file does not exist')\n",
    "        return None\n",
    "\n",
    "    if fname.split('.')[-1] == 'dat':\n",
    "        try:\n",
    "        #print('loading legacy .dat data')\n",
    "            with open(fname, 'rb') as f:\n",
    "                dat = pickle.load(f)\n",
    "        except EOFError:\n",
    "            print('eof error:'+fname)\n",
    "            return None\n",
    "\n",
    "    # format everything into a matlab-friendly thing\n",
    "    ns = len(dat['output'])\n",
    "    #crds = np.array([[dat['output'][k][0][0], dat['output'][k][0][1]] for k in range(ns)])  # assume 2d\n",
    "    crds = np.array([dat['output'][k][0] for k in range(ns)])\n",
    "    KE = np.array([dat['output'][k][1] for k in range(ns)])\n",
    "    jac_pc = np.array([dat['output'][k][2][0] for k in range(ns)])\n",
    "    evals_full = np.array([dat['output'][k][2][1] for k in range(ns)])\n",
    "    D = crds.shape[1]\n",
    "    \n",
    "    \n",
    "\n",
    "    # filter the data into slow and fast points, then cluster to get the effecgtive points\n",
    "    # create cutoffs for fixed points and slow points. filter data\n",
    "    mask_fixed = KE < 0.0001\n",
    "\n",
    "    # define slow points that only change magnitude < 5% across duration of trial\n",
    "    lam = 2.5\n",
    "    dt = 0.05\n",
    "    eps_norm = 0.05\n",
    "    eps_fp = 1e-3\n",
    "    sdiffnorm = 2 * np.sqrt(KE) * lam / (np.linalg.norm(crds, axis=1))\n",
    "    mask_slow = sdiffnorm < eps_norm\n",
    "\n",
    "    mask = (mask_fixed) | (mask_slow)\n",
    "    # potentially get ride of this\n",
    "    mask = np.ones(mask.shape).astype(bool)\n",
    "\n",
    "    crds_masked = crds[mask, :]\n",
    "    KE_masked = KE[mask]\n",
    "    jac_pc_masked = jac_pc[mask, :, :]\n",
    "    evals_full_masked = evals_full[mask, :]\n",
    "    sdiffnorm_masked = sdiffnorm[mask]\n",
    "    isfixed_masked = KE_masked < 0.0001\n",
    "    ns_masked = sum(mask)\n",
    "    \n",
    "    \n",
    "    #decide on hyperparameter\n",
    "    if doadaptive:\n",
    "        xvals = [k[0][0] for k in dat['crds']]\n",
    "        xrange = max(xvals)-min(xvals)\n",
    "        eps = np.abs(xrange*eps)\n",
    "        if eps==0:\n",
    "            print('issue with range')\n",
    "            return None\n",
    "        \n",
    "    \n",
    "    #find number of dynamical systems features\n",
    "    clustering = dbscan(eps=eps, min_samples=10).fit(crds_masked)\n",
    "    labs = np.unique(clustering.labels_)\n",
    "    labels = clustering.labels_\n",
    "    \n",
    "    #analyze the spread of each feature. relevant only for line attractors, but that analysis is later\n",
    "    featurelen = []\n",
    "    for k in labs:\n",
    "        pts = crds_masked[labels==k]\n",
    "        featurelen.append(np.max(pairwise_distances(pts)))\n",
    "    \n",
    "    fetdict = dict(zip(labs,featurelen))\n",
    "    \n",
    "    # TODO: determine if each labeled feature is in range. give it a bit of a buffer of 30%\n",
    "    min_pcvals = []\n",
    "    max_pcvals = []\n",
    "    for m in range(D):\n",
    "        min_pcvals.append(1.3*np.min(np.array([k[0][m] for k in dat['crds']])))\n",
    "        max_pcvals.append(1.3*np.max(np.array([k[0][m] for k in dat['crds']])))\n",
    "        \n",
    "    inrange = []  # is each masked fixed/slow point within bounds of PC_min and PC_max?    \n",
    "    for k in crds_masked:\n",
    "        cond_all = True\n",
    "        for m in range(D):\n",
    "            cond_m = k[m] > min_pcvals[m] and k[m] < max_pcvals[m]  # if out of range for any PC\n",
    "            cond_all = cond_all and cond_m\n",
    "        inrange.append(cond_all)\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    savedict = {'ns': ns_masked, 'crds': crds_masked, 'KE': KE_masked, 'jac_pc': jac_pc_masked,\n",
    "                'evals_full_masked': evals_full, 'statediff': sdiffnorm_masked, 'labels': labels,\n",
    "                'isfixed': isfixed_masked, 'fetdict':fetdict, 'D':D, 'inrange':inrange}\n",
    "    if dosave:\n",
    "        if savedir is None:\n",
    "            savemat(fname.split('.')[0] + '.mat', savedict)\n",
    "        else:\n",
    "            savename = savedir + fname.split('/')[-1].split('.')[0]+'.mat'\n",
    "            savemat(savename, savedict)\n",
    "    return savedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da276dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/dh148/dynamics/results/rnn/ac/20231003/pkind_mem/dynamics/KEmin_constrained/kemin_rnn_curric_10_block_20reg_0_mixed_wait.dat'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "ttype = 'pkind_mem'\n",
    "epoch = 'wait'\n",
    "reg_idx = 1\n",
    "\n",
    "def getdirname(ttype,epoch, num=None, reg_idx = 0, timedep=False):\n",
    "\n",
    "    if not timedep:\n",
    "        if ttype == 'full_cl_old':\n",
    "            #dirname = '/Users/dhocker/projects/dynamics/results/rnn/ac/20230206_fullclstudy/full_cl_redo/dynamics/'  \n",
    "            dirname = '/scratch/dh148/dynamics/results/rnn/ac/20230206_clstudy/full_cl_redo/dynamics/KEmin_constrained/' \n",
    "            if epoch == 'wait':\n",
    "                txt = 'kemin_rnn_curric_*block_10reg_'+str(reg_idx)+'_D2_wait.dat'\n",
    "            elif epoch == 'iti':\n",
    "                txt = 'kemin_rnn_curric_*block_10reg_'+str(reg_idx)+'_D2_iti.dat'\n",
    "            elif epoch == 'start':\n",
    "                txt = 'kemin_rnn_curric_*block_10reg_'+str(reg_idx)+'_D2_start.dat'\n",
    "            dirnames = glob.glob(dirname+txt)\n",
    "            tphase = 5*np.ones((len(dirnames)))\n",
    "        elif ttype == 'full_cl':\n",
    "            #dirname = '/Users/dhocker/projects/dynamics/results/rnn/ac/20230206_fullclstudy/full_cl_redo/dynamics/'  \n",
    "            #dirname = '/scratch/dh148/dynamics/results/rnn/ac/20230206_clstudy/full_cl_redo/dynamics/KEmin_constrained/' \n",
    "            dirname = '/scratch/dh148/dynamics/results/rnn/ac/20231003/full_cl/dynamics/KEmin_constrained/' \n",
    "            if epoch == 'wait':\n",
    "                txt = 'kemin_rnn_curric_*block_10reg_'+str(reg_idx)+'_mixed_wait.dat'\n",
    "            elif epoch == 'iti':\n",
    "                txt = 'kemin_rnn_curric_*block_10reg_'+str(reg_idx)+'_mixed_iti.dat'\n",
    "            elif epoch == 'start':\n",
    "                txt = 'kemin_rnn_curric_*block_10reg_'+str(reg_idx)+'_mixed_start.dat'\n",
    "            dirnames = glob.glob(dirname+txt)\n",
    "            tphase = 5*np.ones((len(dirnames)))\n",
    "        elif ttype == 'nok_cl':\n",
    "            #dirname = '/Users/dhocker/projects/dynamics/results/rnn/ac/20230206_fullclstudy/nok_cl/dynamics/'\n",
    "            dirname = '/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/' \n",
    "            if epoch == 'wait':\n",
    "                txt = 'kemin_rnn_curric_*block_60reg_'+str(reg_idx)+'_mixed_wait.dat'\n",
    "            elif epoch == 'iti':\n",
    "                txt = 'kemin_rnn_curric_*block_60reg_'+str(reg_idx)+'_mixed_iti.dat'\n",
    "            elif epoch == 'start':\n",
    "                txt = 'kemin_rnn_curric_*block_60reg_'+str(reg_idx)+'_mixed_start.dat'\n",
    "            dirnames = glob.glob(dirname+txt)\n",
    "            tphase = 5*np.ones((len(dirnames)))\n",
    "        elif ttype == 'pkind_mem':\n",
    "            #dirname = '/Users/dhocker/projects/dynamics/results/rnn/ac/20230206_fullclstudy/nok_cl/dynamics/'\n",
    "            dirname = '/scratch/dh148/dynamics/results/rnn/ac/20231003/pkind_mem/dynamics/KEmin_constrained/' \n",
    "            if epoch == 'wait':\n",
    "                txt = 'kemin_rnn_curric_*block_20reg_'+str(reg_idx)+'_mixed_wait.dat'\n",
    "            elif epoch == 'iti':\n",
    "                txt = 'kemin_rnn_curric_*block_20reg_'+str(reg_idx)+'_mixed_iti.dat'\n",
    "            elif epoch == 'start':\n",
    "                txt = 'kemin_rnn_curric_*block_20reg_'+str(reg_idx)+'_mixed_start.dat'\n",
    "            dirnames = glob.glob(dirname+txt)\n",
    "            tphase = 5*np.ones((len(dirnames)))\n",
    "\n",
    "    else:\n",
    "        \n",
    "        assert num is not None, \"num must be supplied for timedep=True option. single RNNs only\"\n",
    "        \n",
    "        if ttype == 'full_cl':\n",
    "            idxmax_block = 10\n",
    "        elif ttype == 'nok_cl':\n",
    "            idxmax_block = 20\n",
    "        elif ttype == 'pkind_mem':\n",
    "            idxmax_block = 20\n",
    "        else:\n",
    "            print('issue with choosing ttype')\n",
    "\n",
    "            \n",
    "        #dirname = '/scratch/dh148/dynamics/results/rnn/ac/20230206_clstudy/full_cl_redo/dynamics/KEmin_constrained/'       \n",
    "        dirname = '/scratch/dh148/dynamics/results/rnn/ac/20231003/'+ttype+'/dynamics/KEmin_constrained/'     \n",
    "        dirnames = []\n",
    "        tphase = []\n",
    "\n",
    "\n",
    "        \n",
    "        # mse kindergarten\n",
    "        if ttype == 'full_cl':\n",
    "            txt = 'kemin_rnn_kindergarten_'+str(num)+'_simplereg_'+str(reg_idx)+'_kind_'+epoch+'.dat'\n",
    "            dirnames.append(dirname+txt)\n",
    "            tphase.append(0)\n",
    "            \n",
    "            for k in range(1,11):\n",
    "                txt = 'kemin_rnn_kindergarten_'+str(num)+'_int_0_'+str(k)+'reg_'+str(reg_idx)+'_kind_'+epoch+'.dat'\n",
    "                dirnames.append(dirname+txt)\n",
    "            tphase.extend(1*np.ones((10,)))\n",
    "            \n",
    "        if ttype == 'pkind_mem':\n",
    "            \n",
    "            for k in range(1,11):\n",
    "                txt = 'kemin_rnn_kindergarten_'+str(num)+'_int_0_'+str(k)+'reg_'+str(reg_idx)+'_mixed_'+epoch+'.dat'\n",
    "                dirnames.append(dirname+txt)\n",
    "            tphase.extend(1*np.ones((10,)))\n",
    "        \n",
    "        \n",
    "        # inference\n",
    "        if ttype == 'full_cl':\n",
    "            for k in range(1,101,1):\n",
    "                txt = 'kemin_rnn_pred_'+str(num)+'_'+str(k)+'reg_'+str(reg_idx)+'_kind_'+epoch+'.dat'\n",
    "                dirnames.append(dirname+txt)\n",
    "            tphase.extend(2*np.ones((100,)))\n",
    "\n",
    "        # task\n",
    "        for k in range(1,11):\n",
    "            txt = 'kemin_rnn_curric_'+str(num)+'_nocatch_'+str(k)+'reg_'+str(reg_idx)+'_mixed_'+epoch+'.dat'\n",
    "            dirnames.append(dirname+txt)\n",
    "        tphase.extend(3*np.ones((10,)))\n",
    "        for k in range(1,11):\n",
    "            txt = 'kemin_rnn_curric_'+str(num)+'_catch_'+str(k)+'reg_'+str(reg_idx)+'_mixed_'+epoch+'.dat'\n",
    "            dirnames.append(dirname+txt)\n",
    "        tphase.extend(4*np.ones((10,)))\n",
    "        for k in range(1,idxmax_block+1):\n",
    "            txt = 'kemin_rnn_curric_'+str(num)+'_block_'+str(k)+'reg_'+str(reg_idx)+'_mixed_'+epoch+'.dat'\n",
    "            dirnames.append(dirname+txt)\n",
    "        tphase.extend(5*np.ones((idxmax_block,)))\n",
    "\n",
    "    \n",
    "    \n",
    "    return dirnames, tphase\n",
    "dirnames, tphase = getdirname(ttype,epoch,timedep=True, num=10)\n",
    "dirnames[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75cc7679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_gen(eigs,D=2):\n",
    "    \"\"\"will classify eigenvalues in arbitraty dim as \n",
    "      - attractor (stable) both < 1\n",
    "      - source (unstable) both > 1\n",
    "      - saddle (semistable eig_1 < 1, eig2 > 1)\n",
    "      - line attractor (one eig is unity, within a tolerance)\n",
    "      \n",
    "      (handle these later. need to check textbook)\n",
    "      - stablespiral (complex eigenvalues), norm < 1\n",
    "      - unstable spiral (complex)\n",
    "      - orbit (purely imaginary)\"\"\"\n",
    "    \n",
    "    tol1_low = 0.999\n",
    "    tol1_high = 1.001\n",
    "    \n",
    "    ltmask = eigs < tol1_low # attractors\n",
    "    gtmask = eigs > tol1_high # unstable\n",
    "    linemask = (eigs > tol1_low) & (eigs < tol1_high) #lines\n",
    "    \n",
    "    if np.sum(ltmask) == D:\n",
    "        return 'attractor'\n",
    "    elif np.sum(gtmask) == D:\n",
    "        return 'source'\n",
    "    elif np.sum(linemask) > 0:\n",
    "        return 'line'\n",
    "    elif np.sum(ltmask) > 0 and np.sum(gtmask) > 0:\n",
    "        return 'saddle'\n",
    "    else:\n",
    "        print('i missed something'+ str(eigs))\n",
    "        return None\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9fc4556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getnpts(dirnames,tphase, subtype='fixed', eps=3, doadaptive=False, savedir=None, restrictrange=False):\n",
    "    \"\"\"helper script to get number and type of fixed points\n",
    "        if savedir is None: defautl to saving things in datadir. useful for different eps runs\n",
    "        restrictrange is for excluding feature outside range of PC activity \"\"\"\n",
    "    nfixed_all = []\n",
    "    nslow_all = []\n",
    "    ntot = []\n",
    "    \n",
    "    nattractor_all = []\n",
    "    nsaddle_all = []\n",
    "    nline_all = []\n",
    "    nsource_all = []\n",
    "    ctr = 0\n",
    "    cutctr = 0\n",
    "    \n",
    "    dirnamecpy = copy.deepcopy(dirnames)\n",
    "    tphasecpy = copy.deepcopy(tphase)\n",
    "    \n",
    "    fetlen_all = []\n",
    "    fetlentype_all = []\n",
    "    inrange_all = []\n",
    "    Dall = []\n",
    "    \n",
    "    for m in dirnames:\n",
    "        #try:\n",
    "        if savedir is None:\n",
    "            dosave = False\n",
    "        else:\n",
    "            dosave = True\n",
    "\n",
    "        dat = KEconvert2matlab(m,dosave = dosave, eps=eps, doadaptive=doadaptive, savedir=savedir)\n",
    "        #except:\n",
    "        #    print('issue with file:'+m)\n",
    "        #    dat = None\n",
    "        \n",
    "        if dat is None:\n",
    "            #print('didnt exist: '+m)        \n",
    "            nfixed = np.nan\n",
    "            nslow = np.nan\n",
    "            nattractor = np.nan\n",
    "            nsaddle = np.nan\n",
    "            nline = np.nan\n",
    "            nsource = np.nan\n",
    "            npts = []\n",
    "            D = np.nan\n",
    "            #maximum length of feature, and its type\n",
    "            fetlen = []\n",
    "            fetlentype = []\n",
    "\n",
    "        else:\n",
    "            D = dat['D']\n",
    "            \n",
    "            if restrictrange:\n",
    "                mask = dat['inrange']\n",
    "            else:\n",
    "                mask = np.ones(len(dat['labels'])).astype(bool)            \n",
    "                \n",
    "            npts = np.unique(dat['labels'][np.array(dat['labels']>-1) & np.array(mask)])\n",
    "\n",
    "            nfixed = 0\n",
    "            nslow = 0\n",
    "            nattractor = 0\n",
    "            nsaddle = 0\n",
    "            nline = 0\n",
    "            nsource = 0\n",
    "            \n",
    "            #maximum length of feature, and its type\n",
    "            fetlen = []\n",
    "            fetlentype = []\n",
    "            \n",
    "            #also track if feature is is in the range of network activity\n",
    "            inrange = []\n",
    "\n",
    "\n",
    "            for k in npts:\n",
    "                pt_k_idx = np.argwhere(dat['labels']==k)[0,0]\n",
    "                \n",
    "                fetlen.append(dat['fetdict'][k])\n",
    "                inrange.append(dat['inrange'][k])\n",
    "                \n",
    "                \n",
    "                if dat['isfixed'][pt_k_idx]:\n",
    "                    nfixed+=1\n",
    "                else:\n",
    "                    nslow+=1\n",
    "\n",
    "                test = schur(dat['jac_pc'][pt_k_idx], output='real')\n",
    "                evals = np.diag(test[0])\n",
    "                #c = classify(evals)\n",
    "                c = classify_gen(evals,D)\n",
    "                #types.append(c)\n",
    "                \n",
    "                #add points only if following condition is met\n",
    "                cond1 = dat['isfixed'][pt_k_idx] and subtype=='fixed' #update only if fixed\n",
    "                cond2 = not dat['isfixed'][pt_k_idx] and subtype=='slow' #update only if slow\n",
    "                cond3 = subtype == 'all' #update all of them\n",
    "\n",
    "                #only update if fixed\n",
    "                if cond1 or cond2 or cond3:\n",
    "                    if c == 'attractor':\n",
    "                        nattractor +=1\n",
    "                        fetlentype.append('attractor')\n",
    "                    elif c == 'saddle':\n",
    "                        nsaddle +=1\n",
    "                        fetlentype.append('saddle')\n",
    "                    elif c == 'line':\n",
    "                        nline +=1\n",
    "                        fetlentype.append('line')\n",
    "                    elif c == 'source':\n",
    "                        nsource +=1     \n",
    "                        fetlentype.append('source')\n",
    "                    else:\n",
    "                        print('none chosen')\n",
    "                        \n",
    "\n",
    "        nfixed_all.append(nfixed)\n",
    "        nslow_all.append(nslow)\n",
    "        ntot.append(len(npts))\n",
    "        nattractor_all.append(nattractor)\n",
    "        nsaddle_all.append(nsaddle)\n",
    "        nline_all.append(nline)\n",
    "        nsource_all.append(nsource)\n",
    "        fetlen_all.append(fetlen)\n",
    "        fetlentype_all.append(fetlentype)\n",
    "        Dall.append(D)\n",
    "        inrange_all.append(inrange)\n",
    "        \n",
    "\n",
    "        \n",
    "    typelist = [nattractor_all, nsaddle_all, nline_all, nsource_all]\n",
    "\n",
    "    \n",
    "    return nfixed_all, nslow_all, ntot, typelist, dirnamecpy, tphasecpy, fetlen_all, fetlentype_all, Dall, inrange_all\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71d4bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fig. E. the end-of-training cumulative plot\n",
    "\n",
    "st = 'all'\n",
    "vers = 'full_cl'  #\n",
    "\n",
    "#reg_idx = 0 # for OFC results\n",
    "reg_idx = 1  # for STR results\n",
    "\n",
    "\n",
    "savedir = None\n",
    "\n",
    "\n",
    "eps = 0.01  # ratio of PC1 range\n",
    "doadaptive = True\n",
    "restrictrange = False\n",
    "\n",
    "dirnames, tphase = getdirname(vers,'wait', reg_idx=reg_idx)\n",
    "npts_kind_wait = getnpts(dirnames,tphase,st, eps=eps, doadaptive=doadaptive,savedir=savedir, restrictrange=restrictrange)\n",
    "\n",
    "dirnames, tphase = getdirname(vers,'iti', reg_idx=reg_idx)\n",
    "npts_kind_iti = getnpts(dirnames,tphase,st, eps=eps, doadaptive=doadaptive,savedir=savedir,restrictrange=restrictrange)\n",
    "\n",
    "dirnames, tphase = getdirname(vers,'start', reg_idx=reg_idx)\n",
    "npts_kind_start = getnpts(dirnames,tphase,st, eps=eps, doadaptive=doadaptive,savedir=savedir,restrictrange=restrictrange)\n",
    "\n",
    "\n",
    "dirnames, tphase = getdirname('nok_cl','wait', reg_idx=reg_idx)\n",
    "npts_classic_wait = getnpts(dirnames,tphase,st, eps=eps, doadaptive=doadaptive,savedir=savedir,restrictrange=restrictrange)\n",
    "\n",
    "dirnames, tphase = getdirname('nok_cl','iti', reg_idx=reg_idx)\n",
    "npts_classic_iti = getnpts(dirnames,tphase,st, eps=eps, doadaptive=doadaptive,savedir=savedir,restrictrange=restrictrange)\n",
    "\n",
    "dirnames, tphase = getdirname('nok_cl','start', reg_idx=reg_idx)\n",
    "npts_classic_start = getnpts(dirnames,tphase,st, eps=eps, doadaptive=doadaptive,savedir=savedir,restrictrange=restrictrange)\n",
    "\n",
    "\n",
    "dirnames, tphase = getdirname('pkind_mem','wait', reg_idx=reg_idx)\n",
    "npts_mem_wait = getnpts(dirnames,tphase,st, eps=eps, doadaptive=doadaptive,savedir=savedir,restrictrange=restrictrange)\n",
    "\n",
    "dirnames, tphase = getdirname('pkind_mem','iti', reg_idx=reg_idx)\n",
    "npts_mem_iti = getnpts(dirnames,tphase,st, eps=eps, doadaptive=doadaptive,savedir=savedir,restrictrange=restrictrange)\n",
    "\n",
    "dirnames, tphase = getdirname('pkind_mem','start', reg_idx=reg_idx)\n",
    "npts_mem_start = getnpts(dirnames,tphase,st, eps=eps, doadaptive=doadaptive,savedir=savedir,restrictrange=restrictrange)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06ec5b80-77e3-4ff3-8cdb-07c98cba4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to save intermediate files?\n",
    "savedict = {'npts_kind_wait':npts_kind_wait, 'npts_kind_iti':npts_kind_iti, 'npts_kind_start':npts_kind_start,\n",
    "            'npts_classic_wait':npts_classic_wait, 'npts_classic_iti':npts_classic_iti, 'npts_classic_start':npts_classic_start,\n",
    "            'npts_mem_wait':npts_mem_wait, 'npts_mem_iti':npts_mem_iti, 'npts_mem_start':npts_mem_start}\n",
    "\n",
    "dbase = '/scratch/dh148/dynamics/results/rnn/ac/20231003/figs/'\n",
    "with open(dbase+'ke_results_str_wait_all3.dat','wb') as f:\n",
    "    test = pickle.dump(savedict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29fc107b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-51259474/ipykernel_2366509/357363892.py:46: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  sdiffnorm = 2 * np.sqrt(KE) * lam / (np.linalg.norm(crds, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "1\n",
      "2\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "3\n",
      "issue with range\n",
      "issue with range\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "8\n",
      "9\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "10\n",
      "11\n",
      "issue with range\n",
      "12\n",
      "13\n",
      "issue with range\n",
      "issue with range\n",
      "14\n",
      "15\n",
      "issue with range\n",
      "16\n",
      "17\n",
      "issue with range\n",
      "issue with range\n",
      "18\n",
      "19\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "20\n",
      "21\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "22\n",
      "23\n",
      "issue with range\n",
      "24\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "25\n",
      "26\n",
      "27\n",
      "issue with range\n",
      "28\n",
      "issue with range\n",
      "issue with range\n",
      "29\n",
      "30\n",
      "issue with range\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "issue with range\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "41\n",
      "42\n",
      "43\n",
      "issue with range\n",
      "issue with range\n",
      "issue with range\n",
      "44\n",
      "issue with range\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# try the pop average\n",
    "npts_all = []\n",
    "npts_all_str = []\n",
    "\n",
    "dims_all = []\n",
    "dims_all_str = []\n",
    "\n",
    "#userange = range(1,21)\n",
    "#userange = [2,3,4,5,6,7,8,9,10,11,13,14,15,16,18,19]  #until all networks are done\n",
    "userange = range(1,51)\n",
    "\n",
    "eps = 0.01\n",
    "doadaptive = True\n",
    "timedep = True\n",
    "\n",
    "\n",
    "for j in userange:\n",
    "    print(j)\n",
    "    st = 'all'\n",
    "    ttype = 'full_cl'\n",
    "    epoch = 'wait'\n",
    "    num = j\n",
    "    reg_idx = 0\n",
    "    dirnames, tphase = getdirname(ttype,epoch,num,reg_idx,timedep=timedep)\n",
    "    npts_kind_wait = getnpts(dirnames,tphase,st, eps=eps, doadaptive=doadaptive)\n",
    "    npts_j = np.array(npts_kind_wait[0])+np.array(npts_kind_wait[1])\n",
    "    npts_all.append(npts_j)\n",
    "    dims_all.append(npts_kind_wait[-2])\n",
    "    \n",
    "for j in userange:\n",
    "    print(j)\n",
    "    st = 'all'\n",
    "    ttype = 'full_cl'\n",
    "    epoch = 'wait'\n",
    "    num = j\n",
    "    reg_idx = 1\n",
    "    dirnames, tphase_str = getdirname(ttype,epoch,num,reg_idx,timedep=timedep)\n",
    "    npts_kind_wait = getnpts(dirnames,tphase,st, eps=eps, doadaptive=doadaptive)\n",
    "    npts_j = np.array(npts_kind_wait[0])+np.array(npts_kind_wait[1])\n",
    "    npts_all_str.append(npts_j)\n",
    "    dims_all_str.append(npts_kind_wait[-2])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cdc81c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dosave = True\n",
    "doload = False\n",
    "\n",
    "if dosave:\n",
    "\n",
    "    savedir = '/scratch/dh148/dynamics/results/rnn/ac/20231003/figs/'\n",
    "    savename = savedir + 'ke_overtraining.dat'\n",
    "\n",
    "    with open(savename,'wb') as f:\n",
    "        pickle.dump([npts_all,npts_all_str,dims_all, dims_all_str,tphase, tphase_str],f)\n",
    "        \n",
    "if doload:\n",
    "    savedir = '/scratch/dh148/dynamics/results/rnn/ac/20231003/figs/'\n",
    "    savename = savedir + 'ke_overtraining.dat'\n",
    "\n",
    "    with open(savename,'rb') as f:\n",
    "        [npts_all,npts_all_str,dims_all, dims_all_str,tphase, tphase_str] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8d0448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_2_block_14reg_0_mixed_wait.dat\n",
      "3\n",
      "4\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_4_block_6reg_0_mixed_wait.dat\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_4_block_15reg_0_mixed_wait.dat\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_9_block_4reg_0_mixed_wait.dat\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_9_block_14reg_0_mixed_wait.dat\n",
      "10\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_10_block_8reg_0_mixed_wait.dat\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_16_block_16reg_0_mixed_wait.dat\n",
      "17\n",
      "18\n",
      "19\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_19_block_15reg_0_mixed_wait.dat\n",
      "20\n",
      "1\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_1_block_10reg_1_mixed_wait.dat\n",
      "2\n",
      "3\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_3_block_8reg_1_mixed_wait.dat\n",
      "4\n",
      "5\n",
      "6\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_6_block_4reg_1_mixed_wait.dat\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_6_block_16reg_1_mixed_wait.dat\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_12_block_14reg_1_mixed_wait.dat\n",
      "13\n",
      "14\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_14_block_15reg_1_mixed_wait.dat\n",
      "15\n",
      "16\n",
      "17\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_17_block_15reg_1_mixed_wait.dat\n",
      "18\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_18_block_16reg_1_mixed_wait.dat\n",
      "19\n",
      "20\n",
      "eof error:/scratch/dh148/dynamics/results/rnn/ac/20231003/nok_cl/dynamics/KEmin_constrained/kemin_rnn_curric_20_block_4reg_1_mixed_wait.dat\n"
     ]
    }
   ],
   "source": [
    "# do it for shaping only and memory\n",
    "\n",
    "# try the pop average\n",
    "npts_all_shp = []\n",
    "npts_all_shp_str = []\n",
    "\n",
    "dims_all_shp = []\n",
    "dims_all_shp_str = []\n",
    "\n",
    "#userange = range(1,21)\n",
    "#userange = [2,3,4,5,6,7,8,9,10,11,13,14,15,16,18,19]  #until all networks are done\n",
    "userange = range(1,21)\n",
    "\n",
    "eps = 0.01\n",
    "doadaptive = True\n",
    "timedep = True\n",
    "\n",
    "\n",
    "for j in userange:\n",
    "    print(j)\n",
    "    st = 'all'\n",
    "    ttype = 'nok_cl'\n",
    "    epoch = 'wait'\n",
    "    num = j\n",
    "    reg_idx = 0\n",
    "    dirnames_shp, tphase_shp = getdirname(ttype,epoch,num,reg_idx,timedep=timedep)\n",
    "    npts_kind_wait = getnpts(dirnames_shp,tphase_shp,st, eps=eps, doadaptive=doadaptive)\n",
    "    npts_j = np.array(npts_kind_wait[0])+np.array(npts_kind_wait[1])\n",
    "    npts_all_shp.append(npts_j)\n",
    "    dims_all_shp.append(npts_kind_wait[-2])\n",
    "\n",
    "for j in userange:\n",
    "    print(j)\n",
    "    st = 'all'\n",
    "    ttype = 'nok_cl'\n",
    "    epoch = 'wait'\n",
    "    num = j\n",
    "    reg_idx = 1\n",
    "    dirnames_shp, tphase_shp_str = getdirname(ttype,epoch,num,reg_idx,timedep=timedep)\n",
    "    npts_kind_wait = getnpts(dirnames_shp,tphase_shp_str,st, eps=eps, doadaptive=doadaptive)\n",
    "    npts_j = np.array(npts_kind_wait[0])+np.array(npts_kind_wait[1])\n",
    "    npts_all_shp_str.append(npts_j)\n",
    "    dims_all_shp_str.append(npts_kind_wait[-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e8a07f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dosave = False\n",
    "doload = True\n",
    "\n",
    "if dosave:\n",
    "\n",
    "    savedir = '/scratch/dh148/dynamics/results/rnn/ac/20231003/figs/'\n",
    "    savename = savedir + 'ke_overtraining_shp.dat'\n",
    "\n",
    "    with open(savename,'wb') as f:\n",
    "        pickle.dump([npts_all_shp,npts_all_shp_str,dims_all_shp, dims_all_shp_str,tphase_shp, tphase_shp_str],f)\n",
    "        \n",
    "if doload:\n",
    "    savedir = '/scratch/dh148/dynamics/results/rnn/ac/20231003/figs/'\n",
    "    savename = savedir + 'ke_overtraining_shp.dat'\n",
    "\n",
    "    with open(savename,'rb') as f:\n",
    "        [npts_all_shp,npts_all_shp_str,dims_all_shp, dims_all_shp_str,tphase_shp, tphase_shp_str] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8bc15f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-51152904/ipykernel_3056694/357363892.py:46: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  sdiffnorm = 2 * np.sqrt(KE) * lam / (np.linalg.norm(crds, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-51152904/ipykernel_3056694/357363892.py:46: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  sdiffnorm = 2 * np.sqrt(KE) * lam / (np.linalg.norm(crds, axis=1))\n",
      "/state/partition1/job-51152904/ipykernel_3056694/357363892.py:46: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  sdiffnorm = 2 * np.sqrt(KE) * lam / (np.linalg.norm(crds, axis=1))\n",
      "/state/partition1/job-51152904/ipykernel_3056694/357363892.py:46: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  sdiffnorm = 2 * np.sqrt(KE) * lam / (np.linalg.norm(crds, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-51152904/ipykernel_3056694/357363892.py:46: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  sdiffnorm = 2 * np.sqrt(KE) * lam / (np.linalg.norm(crds, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-51152904/ipykernel_3056694/357363892.py:46: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  sdiffnorm = 2 * np.sqrt(KE) * lam / (np.linalg.norm(crds, axis=1))\n"
     ]
    }
   ],
   "source": [
    "# memory\n",
    "# do it for shaping only and memory\n",
    "\n",
    "# try the pop average\n",
    "npts_all_mem = []\n",
    "npts_all_mem_str = []\n",
    "\n",
    "dims_all_mem = []\n",
    "dims_all_mem_str = []\n",
    "\n",
    "userange = range(1,21)\n",
    "\n",
    "eps = 0.01\n",
    "doadaptive = True\n",
    "timedep = True\n",
    "\n",
    "\n",
    "for j in userange:\n",
    "    print(j)\n",
    "    st = 'all'\n",
    "    ttype = 'pkind_mem'\n",
    "    epoch = 'wait'\n",
    "    num = j\n",
    "    reg_idx = 0\n",
    "    dirnames_mem, tphase_mem = getdirname(ttype,epoch,num,reg_idx,timedep=timedep)\n",
    "    npts_kind_wait = getnpts(dirnames_mem,tphase_mem,st, eps=eps, doadaptive=doadaptive)\n",
    "    npts_j = np.array(npts_kind_wait[0])+np.array(npts_kind_wait[1])\n",
    "    npts_all_mem.append(npts_j)\n",
    "    dims_all_mem.append(npts_kind_wait[-2])\n",
    "\n",
    "for j in userange:\n",
    "    print(j)\n",
    "    st = 'all'\n",
    "    ttype = 'pkind_mem'\n",
    "    epoch = 'wait'\n",
    "    num = j\n",
    "    reg_idx = 1\n",
    "    dirnames_mem, tphase_mem_str = getdirname(ttype,epoch,num,reg_idx,timedep=timedep)\n",
    "    #print(dirnames_mem)\n",
    "    npts_kind_wait = getnpts(dirnames_mem,tphase_mem_str,st, eps=eps, doadaptive=doadaptive)\n",
    "    npts_j = np.array(npts_kind_wait[0])+np.array(npts_kind_wait[1])\n",
    "    npts_all_mem_str.append(npts_j)\n",
    "    dims_all_mem_str.append(npts_kind_wait[-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2159cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dosave = False\n",
    "doload = True\n",
    "\n",
    "if dosave:\n",
    "\n",
    "    savedir = '/scratch/dh148/dynamics/results/rnn/ac/20231003/figs/'\n",
    "    savename = savedir + 'ke_overtraining_mem.dat'\n",
    "\n",
    "    with open(savename,'wb') as f:\n",
    "        pickle.dump([npts_all_mem,npts_all_mem_str,dims_all_mem, dims_all_mem_str,tphase_mem, tphase_mem_str],f)\n",
    "        \n",
    "if doload:\n",
    "    savedir = '/scratch/dh148/dynamics/results/rnn/ac/20231003/figs/'\n",
    "    savename = savedir + 'ke_overtraining_mem.dat'\n",
    "\n",
    "    with open(savename,'rb') as f:\n",
    "        [npts_all_mem,npts_all_mem_str,dims_all_mem, dims_all_mem_str, tphase_mem, tphase_mem_str] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd08fb3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
